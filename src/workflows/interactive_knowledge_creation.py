"""
Interactive Knowledge Creation Workflow
å¯¾è©±çš„ãƒŠãƒ¬ãƒƒã‚¸ç”Ÿæˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼

Claude Code Workflow Studio ã‚’æ´»ç”¨ã—ãŸå¯¾è©±å‹ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
AIé§†å‹•ã«ã‚ˆã‚‹è‡ªç„¶è¨€èªç†è§£ã¨æƒ…å ±æŠ½å‡º
"""

import json
import logging
import os
import sys
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional

project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from src.core.itsm_classifier import ITSMClassifier
from src.core.workflow import WorkflowEngine
from src.mcp.sqlite_client import SQLiteClient

logger = logging.getLogger(__name__)


class InteractiveKnowledgeCreationWorkflow:
    """å¯¾è©±çš„ãƒŠãƒ¬ãƒƒã‚¸ç”Ÿæˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ï¼ˆAIé§†å‹•ç‰ˆï¼‰"""

    def __init__(self):
        self.conversation_history = []
        self.collected_info = {
            "title": None,
            "when": None,
            "system": None,
            "symptom": None,
            "impact": None,
            "response": None,
            "cause": None,
            "measures": None,
        }
        self.db_client = SQLiteClient()
        self.itsm_classifier = ITSMClassifier()

        # AI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
        self._ai_client = None
        self._init_ai_client()

    def _init_ai_client(self):
        """AIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–ï¼ˆAnthropicã‚’ãƒ—ãƒ©ã‚¤ãƒãƒªã¨ã—ã¦ä½¿ç”¨ï¼‰"""
        # ãƒ—ãƒ©ã‚¤ãƒãƒª: Anthropicï¼ˆClaudeï¼‰- ã‚¯ã‚©ãƒ¼ã‚¿å•é¡ŒãŒå°‘ãªã„
        anthropic_key = os.getenv("ANTHROPIC_API_KEY")
        if anthropic_key:
            try:
                import anthropic

                self._ai_client = anthropic.Anthropic(api_key=anthropic_key)
                self._ai_provider = "anthropic"
                logger.info("å¯¾è©±AIï¼ˆAnthropicï¼‰åˆæœŸåŒ–å®Œäº†")
                return
            except Exception as e:
                logger.warning(f"AnthropicåˆæœŸåŒ–å¤±æ•—: {e}")

        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: OpenAI
        openai_key = os.getenv("OPENAI_API_KEY")
        if openai_key:
            try:
                from openai import OpenAI

                self._ai_client = OpenAI(api_key=openai_key)
                self._ai_provider = "openai"
                logger.info("å¯¾è©±AIï¼ˆOpenAIï¼‰åˆæœŸåŒ–å®Œäº†")
            except Exception as e:
                logger.warning(f"OpenAIåˆæœŸåŒ–å¤±æ•—: {e}")
                self._ai_provider = None

    def start_conversation(self, initial_input: str) -> Dict[str, Any]:
        """
        å¯¾è©±ã‚’é–‹å§‹

        Args:
            initial_input: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æœ€åˆã®å…¥åŠ›

        Returns:
            æ¬¡ã®è³ªå•ã¾ãŸã¯å®Œäº†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        """
        self.conversation_history.append(
            {
                "role": "user",
                "content": initial_input,
                "timestamp": datetime.now().isoformat(),
            }
        )

        # åˆæœŸå…¥åŠ›ã‹ã‚‰æƒ…å ±ã‚’æŠ½å‡º
        self._extract_info_from_input(initial_input)

        # æ¬¡ã®è³ªå•ã‚’ç”Ÿæˆ
        next_question = self._get_next_question()

        if next_question:
            self.conversation_history.append(
                {
                    "role": "assistant",
                    "content": next_question,
                    "timestamp": datetime.now().isoformat(),
                }
            )
            return {
                "type": "question",
                "question": next_question,
                "progress": self._get_progress(),
            }
        else:
            # æƒ…å ±åé›†å®Œäº†ã€ãƒŠãƒ¬ãƒƒã‚¸ç”Ÿæˆ
            return self._generate_knowledge()

    def answer_question(self, answer: str) -> Dict[str, Any]:
        """
        è³ªå•ã¸ã®å›ç­”ã‚’å‡¦ç†

        Args:
            answer: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å›ç­”

        Returns:
            æ¬¡ã®è³ªå•ã¾ãŸã¯ãƒŠãƒ¬ãƒƒã‚¸ç”Ÿæˆçµæœ
        """
        # ç›´å‰ã®è³ªå•ã‚’ä¿å­˜ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ï¼‰
        previous_question = None
        if len(self.conversation_history) >= 1:
            for msg in reversed(self.conversation_history):
                if msg["role"] == "assistant":
                    previous_question = msg["content"]
                    break

        self.conversation_history.append(
            {"role": "user", "content": answer, "timestamp": datetime.now().isoformat()}
        )

        # å›ç­”ã‹ã‚‰æƒ…å ±ã‚’æŠ½å‡º
        self._extract_info_from_input(answer)

        # AIæŠ½å‡ºãŒå¤±æ•—ã—ãŸå ´åˆã€ç›´å‰ã®è³ªå•ã«åŸºã¥ã„ã¦ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’åŸ‹ã‚ã‚‹
        self._fallback_save_answer(answer, previous_question)

        # æ¬¡ã®è³ªå•
        next_question = self._get_next_question()

        if next_question:
            self.conversation_history.append(
                {
                    "role": "assistant",
                    "content": next_question,
                    "timestamp": datetime.now().isoformat(),
                }
            )
            return {
                "type": "question",
                "question": next_question,
                "progress": self._get_progress(),
            }
        else:
            return self._generate_knowledge()

    def _extract_info_from_input(self, text: str):
        """å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰æƒ…å ±ã‚’æŠ½å‡ºï¼ˆAIé§†å‹•ç‰ˆï¼‰"""
        # AIãŒåˆ©ç”¨å¯èƒ½ãªå ´åˆã¯AIæŠ½å‡ºã‚’ä½¿ç”¨
        if self._ai_client:
            self._extract_info_with_ai(text)
        else:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹
            self._extract_info_keyword_based(text)

    def _extract_info_with_ai(self, text: str):
        """AIã‚’ä½¿ã£ã¦æƒ…å ±ã‚’æŠ½å‡º"""
        try:
            # ç¾åœ¨ã®ä¼šè©±å±¥æ­´ã‚’æ•´å½¢
            context = "\n".join(
                [
                    f"{msg['role']}: {msg['content']}"
                    for msg in self.conversation_history[-5:]  # ç›´è¿‘5ä»¶
                ]
            )

            # ç¾åœ¨ã®åé›†çŠ¶æ³
            current_info = json.dumps(
                {k: v for k, v in self.collected_info.items() if v},
                ensure_ascii=False,
                indent=2,
            )

            prompt = f"""ã‚ãªãŸã¯ITã‚µãƒãƒ¼ãƒˆã®æƒ…å ±æŠ½å‡ºã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‹ã‚‰ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆ/ãƒŠãƒ¬ãƒƒã‚¸ã«å¿…è¦ãªæƒ…å ±ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚

ã€ä¼šè©±å±¥æ­´ã€‘
{context}

ã€æœ€æ–°ã®å…¥åŠ›ã€‘
{text}

ã€ç¾åœ¨ã®åé›†æ¸ˆã¿æƒ…å ±ã€‘
{current_info if current_info != '{{}}' else 'ãªã—'}

ä»¥ä¸‹ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«ã¤ã„ã¦ã€å…¥åŠ›ã‹ã‚‰æŠ½å‡ºã§ãã‚‹æƒ…å ±ã‚’JSONå½¢å¼ã§è¿”ã—ã¦ãã ã•ã„ã€‚
æŠ½å‡ºã§ããªã„å ´åˆã¯nullã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚æ—¢ã«åé›†æ¸ˆã¿ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã¯ä¸Šæ›¸ãã—ãªã„ã§ãã ã•ã„ã€‚

ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰:
- title: å•é¡Œã®ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆç°¡æ½”ã«ï¼‰
- when: ã„ã¤ç™ºç”Ÿã—ãŸã‹ï¼ˆæ—¥æ™‚ï¼‰
- system: ã©ã®ã‚·ã‚¹ãƒ†ãƒ /ã‚µãƒ¼ãƒ“ã‚¹ã§ç™ºç”Ÿã—ãŸã‹ï¼ˆâ€»ä»»æ„ã®ã‚·ã‚¹ãƒ†ãƒ åã‚’èªè­˜ã—ã¦ãã ã•ã„ã€‚ä¾‹: Windows11, AresStandard2025, ç¤¾å†…ãƒãƒ¼ã‚¿ãƒ«ãªã©ï¼‰
- symptom: å…·ä½“çš„ãªç—‡çŠ¶ã‚„ã‚¨ãƒ©ãƒ¼å†…å®¹
- impact: å½±éŸ¿ç¯„å›²
- response: å®Ÿæ–½ã—ãŸå¯¾å¿œå†…å®¹
- cause: åŸå› ï¼ˆåˆ¤æ˜ã—ã¦ã„ã‚‹å ´åˆï¼‰
- measures: ä»Šå¾Œã®å¯¾ç­–

JSONå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ï¼ˆèª¬æ˜æ–‡ã¯ä¸è¦ï¼‰:"""

            # ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã«å¿œã˜ãŸAPIå‘¼ã³å‡ºã—
            if getattr(self, "_ai_provider", None) == "anthropic":
                # Anthropic API
                response = self._ai_client.messages.create(
                    model="claude-sonnet-4-20250514",
                    max_tokens=1000,
                    messages=[{"role": "user", "content": prompt}],
                )
                content = response.content[0].text
            else:
                # OpenAI API
                response = self._ai_client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=[
                        {
                            "role": "system",
                            "content": "ã‚ãªãŸã¯ITã‚µãƒãƒ¼ãƒˆã®æƒ…å ±æŠ½å‡ºã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚JSONå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚",
                        },
                        {"role": "user", "content": prompt},
                    ],
                    max_tokens=1000,
                    temperature=0.3,
                )
                content = response.choices[0].message.content

            # JSONæŠ½å‡º
            if "```json" in content:
                content = content.split("```json")[1].split("```")[0]
            elif "```" in content:
                content = content.split("```")[1].split("```")[0]

            extracted = json.loads(content.strip())

            # æŠ½å‡ºã—ãŸæƒ…å ±ã‚’ãƒãƒ¼ã‚¸ï¼ˆæ—¢å­˜æƒ…å ±ã¯ä¸Šæ›¸ãã—ãªã„ï¼‰
            for key, value in extracted.items():
                if (
                    key in self.collected_info
                    and value
                    and not self.collected_info[key]
                ):
                    self.collected_info[key] = value
                    logger.info(
                        f"AIæŠ½å‡º: {key} = {value[:50]}..."
                        if len(str(value)) > 50
                        else f"AIæŠ½å‡º: {key} = {value}"
                    )

        except Exception as e:
            logger.error(f"AIæƒ…å ±æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            self._extract_info_keyword_based(text)

    def _fallback_save_answer(self, answer: str, previous_question: Optional[str]):
        """
        ç›´å‰ã®è³ªå•ã«åŸºã¥ã„ã¦å›ç­”ã‚’ä¿å­˜ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰

        AIæŠ½å‡ºãŒå¤±æ•—ã—ãŸå ´åˆã‚„ã€æŠ½å‡ºçµæœãŒç©ºã®å ´åˆã«ã€
        ç›´å‰ã®è³ªå•å†…å®¹ã‹ã‚‰ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’ç‰¹å®šã—ã¦å›ç­”ã‚’ä¿å­˜ã™ã‚‹
        """
        if not previous_question or not answer or len(answer.strip()) < 2:
            return

        # è³ªå•ã¨ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ãƒãƒƒãƒ”ãƒ³ã‚°
        question_field_map = {
            "ã„ã¤": "when",
            "æ—¥æ™‚": "when",
            "ç™ºç”Ÿ": "when",
            "ã‚·ã‚¹ãƒ†ãƒ ": "system",
            "ã‚µãƒ¼ãƒ“ã‚¹": "system",
            "ç—‡çŠ¶": "symptom",
            "ã‚¨ãƒ©ãƒ¼": "symptom",
            "å½±éŸ¿": "impact",
            "ç¯„å›²": "impact",
            "å¯¾å¿œ": "response",
            "åŸå› ": "cause",
            "å¯¾ç­–": "measures",
            "é˜²æ­¢": "measures",
        }

        # ç›´å‰ã®è³ªå•ã‹ã‚‰ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’ç‰¹å®š
        target_field = None
        for keyword, field in question_field_map.items():
            if keyword in previous_question:
                target_field = field
                break

        # ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒç‰¹å®šã§ãã€ã¾ã å€¤ãŒè¨­å®šã•ã‚Œã¦ã„ãªã„å ´åˆã¯ä¿å­˜
        if target_field and not self.collected_info.get(target_field):
            self.collected_info[target_field] = answer.strip()
            logger.info(f"ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ä¿å­˜: {target_field} = {answer[:50]}...")

    def _extract_info_keyword_based(self, text: str):
        """ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã®æƒ…å ±æŠ½å‡ºï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰"""
        text_lower = text.lower()

        # ã‚¿ã‚¤ãƒˆãƒ«æ¨å®š
        if not self.collected_info["title"]:
            first_sentence = text.split("ã€‚")[0].split("\n")[0]
            if len(first_sentence) > 10:
                self.collected_info["title"] = first_sentence[:100]

        # æ™‚é–“æƒ…å ±
        if any(word in text_lower for word in ["æ˜¨æ—¥", "ä»Šæ—¥", "å…ˆé€±", "æ™‚", "åˆ†"]):
            if not self.collected_info["when"]:
                self.collected_info["when"] = text[:200]

        # ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±ï¼ˆä»»æ„ã®ã‚·ã‚¹ãƒ†ãƒ åã‚‚å—ã‘å…¥ã‚Œã‚‹ï¼‰
        systems = ["web", "db", "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹", "ã‚µãƒ¼ãƒãƒ¼", "ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯", "ãƒ¡ãƒ¼ãƒ«"]
        if any(sys in text_lower for sys in systems):
            if not self.collected_info["system"]:
                self.collected_info["system"] = text[:200]
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒãªãã¦ã‚‚ã€ã‚·ã‚¹ãƒ†ãƒ ã«é–¢ã™ã‚‹è³ªå•ã¸ã®å›ç­”ã¨ã—ã¦æ‰±ã†
        elif not self.collected_info["system"] and len(text) > 2:
            # ç›´å‰ã®è³ªå•ãŒã‚·ã‚¹ãƒ†ãƒ ã«ã¤ã„ã¦ã ã£ãŸå ´åˆã€å›ç­”ã‚’ã‚·ã‚¹ãƒ†ãƒ ã¨ã—ã¦è¨˜éŒ²
            if self.conversation_history:
                last_msg = self.conversation_history[-1]
                if (
                    last_msg["role"] == "assistant"
                    and "ã‚·ã‚¹ãƒ†ãƒ " in last_msg["content"]
                ):
                    self.collected_info["system"] = text[:200]

        # ç—‡çŠ¶
        if any(
            word in text_lower for word in ["ã‚¨ãƒ©ãƒ¼", "éšœå®³", "é…ã„", "åœæ­¢", "ãƒ€ã‚¦ãƒ³"]
        ):
            if not self.collected_info["symptom"]:
                self.collected_info["symptom"] = text[:200]

        # å¯¾å¿œå†…å®¹
        if any(word in text_lower for word in ["å¯¾å¿œ", "å¾©æ—§", "å†èµ·å‹•", "è¨­å®š"]):
            if not self.collected_info["response"]:
                self.collected_info["response"] = text[:200]

    def _get_next_question(self) -> Optional[str]:
        """æ¬¡ã®è³ªå•ã‚’ç”Ÿæˆ"""
        # ä¸è¶³ã—ã¦ã„ã‚‹æƒ…å ±ã‚’ç¢ºèª
        if not self.collected_info["when"]:
            variants = [
                "ã„ã¤é ƒç™ºç”Ÿã—ã¾ã—ãŸã‹ï¼Ÿï¼ˆä¾‹: 1/27 14:30ã€æ˜¨æ—¥ã®æœãªã©ï¼‰",
                "ç™ºç”Ÿã—ãŸæ—¥æ™‚ã¯åˆ†ã‹ã‚Šã¾ã™ã‹ï¼Ÿï¼ˆåˆ†ã‹ã‚‰ãªã‘ã‚Œã°ã€Œä¸æ˜ã€ã§OKã§ã™ï¼‰",
                "ç™ºç”Ÿã‚¿ã‚¤ãƒŸãƒ³ã‚°ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚ï¼ˆã ã„ãŸã„ã®æ™‚é–“å¸¯ã§ã‚‚å¯ï¼‰",
            ]
            return variants[len(self.conversation_history) % len(variants)]

        if not self.collected_info["system"]:
            variants = [
                "ã©ã®ã‚·ã‚¹ãƒ†ãƒ ãƒ»ã‚µãƒ¼ãƒ“ã‚¹ã§ç™ºç”Ÿã—ã¾ã—ãŸã‹ï¼Ÿï¼ˆä¾‹: ãƒ¡ãƒ¼ãƒ«ã€VPNã€ç¤¾å†…ãƒãƒ¼ã‚¿ãƒ«ã€åŸºå¹¹ã‚·ã‚¹ãƒ†ãƒ  ãªã©ï¼‰",
                "å¯¾è±¡ã®ã‚·ã‚¹ãƒ†ãƒ åã¯åˆ†ã‹ã‚Šã¾ã™ã‹ï¼Ÿï¼ˆä¸æ˜ãªã‚‰ã€Œä¸æ˜ã€ã‚„ã€ŒãŠãã‚‰ãã€œã€ã§ã‚‚OKï¼‰",
                "ã©ã®ç”»é¢ãƒ»æ©Ÿèƒ½ã§èµ·ãã¾ã—ãŸã‹ï¼Ÿï¼ˆåˆ†ã‹ã‚‹ç¯„å›²ã§æ§‹ã„ã¾ã›ã‚“ï¼‰",
            ]
            return variants[len(self.conversation_history) % len(variants)]

        if not self.collected_info["symptom"]:
            variants = [
                "å…·ä½“çš„ã«ã©ã‚“ãªç—‡çŠ¶ãƒ»ã‚¨ãƒ©ãƒ¼ã§ã—ãŸã‹ï¼Ÿï¼ˆè¡¨ç¤ºã•ã‚ŒãŸæ–‡è¨€ãŒã‚ã‚Œã°æ•™ãˆã¦ãã ã•ã„ï¼‰",
                "ç¾è±¡ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚ï¼ˆä¾‹: ãƒ­ã‚°ã‚¤ãƒ³ä¸å¯ã€é…ã„ã€ã‚¨ãƒ©ãƒ¼ã‚³ãƒ¼ãƒ‰ãªã©ï¼‰",
                "ã©ã‚“ãªå•é¡ŒãŒèµ·ãã¾ã—ãŸã‹ï¼Ÿï¼ˆã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆãŒã‚ã‚Œã°å†…å®¹ã ã‘ã§OKï¼‰",
            ]
            return variants[len(self.conversation_history) % len(variants)]

        if not self.collected_info["impact"]:
            variants = [
                "å½±éŸ¿ç¯„å›²ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°ã€éƒ¨é–€ã€ã‚·ã‚¹ãƒ†ãƒ ç¯„å›²ãªã©ï¼‰",
                "èª°ã«å½±éŸ¿ã—ã¾ã—ãŸã‹ï¼Ÿï¼ˆå…¨å“¡/ä¸€éƒ¨/ç‰¹å®šéƒ¨é–€ ãªã©ï¼‰",
                "å½±éŸ¿ã®å¤§ãã•ã¯ã©ã®ç¨‹åº¦ã§ã—ãŸã‹ï¼Ÿï¼ˆè»½å¾®/é‡å¤§/æ¥­å‹™åœæ­¢ ãªã©ï¼‰",
            ]
            return variants[len(self.conversation_history) % len(variants)]

        if not self.collected_info["response"]:
            variants = [
                "ã©ã®ã‚ˆã†ã«å¯¾å¿œã—ã¾ã—ãŸã‹ï¼Ÿï¼ˆå®Ÿæ–½ã—ãŸæ‰‹é †ã‚’æ•™ãˆã¦ãã ã•ã„ï¼‰",
                "å¯¾å‡¦å†…å®¹ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚ï¼ˆå†èµ·å‹•/è¨­å®šå¤‰æ›´/é€£çµ¡å…ˆ ãªã©ï¼‰",
                "æš«å®šå¯¾å¿œã‚„å›é¿ç­–ã¯ã‚ã‚Šã¾ã—ãŸã‹ï¼Ÿ",
            ]
            return variants[len(self.conversation_history) % len(variants)]

        if not self.collected_info["cause"]:
            variants = [
                "åŸå› ã¯ç‰¹å®šã§ãã¾ã—ãŸã‹ï¼Ÿï¼ˆåˆ†ã‹ã‚‹ç¯„å›²ã§OKï¼ä¸æ˜ã§ã‚‚å¯ï¼‰",
                "åŸå› ã®è¦‹å½“ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿï¼ˆä¾‹: è¨­å®šå¤‰æ›´ã€è² è·å¢—åŠ  ãªã©ï¼‰",
                "åŸå› ãŒåˆ†ã‹ã‚Œã°æ•™ãˆã¦ãã ã•ã„ã€‚åˆ†ã‹ã‚‰ãªã‘ã‚Œã°ã€Œä¸æ˜ã€ã§å¤§ä¸ˆå¤«ã§ã™ã€‚",
            ]
            return variants[len(self.conversation_history) % len(variants)]

        if not self.collected_info["measures"]:
            variants = [
                "ä»Šå¾Œã®å¯¾ç­–ã‚„å†ç™ºé˜²æ­¢ç­–ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ",
                "åŒæ§˜ã®å•é¡Œã‚’é˜²ããŸã‚ã«è€ƒãˆã¦ã„ã‚‹ã“ã¨ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ",
                "å†ç™ºé˜²æ­¢ã®ãŸã‚ã«ã‚„ã£ã¦ãŠããŸã„ã“ã¨ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ",
            ]
            return variants[len(self.conversation_history) % len(variants)]

        # å…¨ã¦ã®æƒ…å ±ãŒæƒã£ãŸ
        return None

    def _get_progress(self) -> Dict[str, Any]:
        """é€²æ—çŠ¶æ³ã‚’å–å¾—"""
        total_fields = len(self.collected_info)
        filled_fields = sum(1 for v in self.collected_info.values() if v is not None)

        return {
            "filled": filled_fields,
            "total": total_fields,
            "percentage": int(filled_fields / total_fields * 100),
            "collected": {k: bool(v) for k, v in self.collected_info.items()},
        }

    def _generate_knowledge(self) -> Dict[str, Any]:
        """åé›†ã—ãŸæƒ…å ±ã‹ã‚‰ãƒŠãƒ¬ãƒƒã‚¸ã‚’ç”Ÿæˆï¼ˆAIå¼·åŒ–ç‰ˆï¼‰"""
        # AIé§†å‹•ã§ãƒŠãƒ¬ãƒƒã‚¸ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ç”Ÿæˆ
        if self._ai_client:
            return self._generate_knowledge_with_ai()
        else:
            return self._generate_knowledge_basic()

    def _generate_knowledge_with_ai(self) -> Dict[str, Any]:
        """AIã‚’ä½¿ã£ã¦ãƒŠãƒ¬ãƒƒã‚¸ã‚’ç”Ÿæˆ"""
        try:
            # åé›†æƒ…å ±ã‚’JSONå½¢å¼ã§æ•´å½¢
            collected_json = json.dumps(
                self.collected_info, ensure_ascii=False, indent=2
            )

            # ä¼šè©±å±¥æ­´ã‚’æ•´å½¢
            conversation_context = "\n".join(
                [
                    f"{msg['role']}: {msg['content']}"
                    for msg in self.conversation_history
                ]
            )

            prompt = f"""ã‚ãªãŸã¯ITã‚µãƒãƒ¼ãƒˆã®ãƒŠãƒ¬ãƒƒã‚¸ä½œæˆã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã§ã™ã€‚
ä»¥ä¸‹ã®æƒ…å ±ã‹ã‚‰ã€æƒ…ã‚·ã‚¹æ‹…å½“è€…ãŒæ´»ç”¨ã§ãã‚‹é«˜å“è³ªãªãƒŠãƒ¬ãƒƒã‚¸è¨˜äº‹ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

ã€åé›†ã—ãŸæƒ…å ±ã€‘
{collected_json}

ã€å¯¾è©±å±¥æ­´ã€‘
{conversation_context}

ä»¥ä¸‹ã®JSONå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ï¼š
{{
  "title": "ç°¡æ½”ã§åˆ†ã‹ã‚Šã‚„ã™ã„ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆ50æ–‡å­—ä»¥å†…ï¼‰",
  "content": "Markdownå½¢å¼ã®ãƒŠãƒ¬ãƒƒã‚¸æœ¬æ–‡ï¼ˆ## ã‚»ã‚¯ã‚·ãƒ§ãƒ³è¦‹å‡ºã—ã‚’ä½¿ç”¨ï¼‰",
  "summary": "è¦ç´„ï¼ˆ100æ–‡å­—ä»¥å†…ï¼‰",
  "tags": ["ã‚¿ã‚°1", "ã‚¿ã‚°2", "ã‚¿ã‚°3"],
  "recommended_actions": ["æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³1", "æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³2"],
  "prevention_tips": ["å†ç™ºé˜²æ­¢ç­–1", "å†ç™ºé˜²æ­¢ç­–2"]
}}

ãƒŠãƒ¬ãƒƒã‚¸æœ¬æ–‡ã«ã¯ä»¥ä¸‹ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’å«ã‚ã¦ãã ã•ã„ï¼š
- ## æ¦‚è¦
- ## ç™ºç”ŸçŠ¶æ³
- ## å½±éŸ¿ç¯„å›²
- ## å¯¾å¿œæ‰‹é †
- ## åŸå› åˆ†æ
- ## å†ç™ºé˜²æ­¢ç­–
- ## å‚è€ƒæƒ…å ±ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰

JSONå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ï¼ˆèª¬æ˜æ–‡ã¯ä¸è¦ï¼‰:"""

            # APIå‘¼ã³å‡ºã—
            if getattr(self, "_ai_provider", None) == "anthropic":
                response = self._ai_client.messages.create(
                    model="claude-sonnet-4-20250514",
                    max_tokens=2000,
                    messages=[{"role": "user", "content": prompt}],
                )
                content = response.content[0].text
            else:
                response = self._ai_client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=[
                        {
                            "role": "system",
                            "content": "ã‚ãªãŸã¯ITãƒŠãƒ¬ãƒƒã‚¸ä½œæˆã®ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã§ã™ã€‚JSONå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚",
                        },
                        {"role": "user", "content": prompt},
                    ],
                    max_tokens=2000,
                    temperature=0.5,
                )
                content = response.choices[0].message.content

            # JSONæŠ½å‡º
            if "```json" in content:
                content = content.split("```json")[1].split("```")[0]
            elif "```" in content:
                content = content.split("```")[1].split("```")[0]

            ai_result = json.loads(content.strip())
            logger.info("AIé§†å‹•ãƒŠãƒ¬ãƒƒã‚¸ç”Ÿæˆå®Œäº†")

            # ITSMåˆ†é¡
            title = ai_result.get(
                "title", self.collected_info.get("title", "æ–°è¦ãƒŠãƒ¬ãƒƒã‚¸")
            )
            knowledge_content = ai_result.get("content", "")
            classification = self.itsm_classifier.classify(title, knowledge_content)

            # é¡ä¼¼ãƒŠãƒ¬ãƒƒã‚¸æ¤œç´¢
            similar_knowledge = self.db_client.search_knowledge(query=title, limit=5)

            return {
                "type": "knowledge_generated",
                "title": title,
                "content": knowledge_content,
                "summary": ai_result.get("summary", ""),
                "tags": ai_result.get("tags", []),
                "recommended_actions": ai_result.get("recommended_actions", []),
                "prevention_tips": ai_result.get("prevention_tips", []),
                "itsm_type": classification["itsm_type"],
                "confidence": classification["confidence"],
                "similar_knowledge": similar_knowledge,
                "conversation_history": self.conversation_history,
                "ai_generated": True,
                "action": "review_or_save",
            }

        except Exception as e:
            logger.error(f"AIé§†å‹•ãƒŠãƒ¬ãƒƒã‚¸ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return self._generate_knowledge_basic()

    def _generate_knowledge_basic(self) -> Dict[str, Any]:
        """åŸºæœ¬çš„ãªãƒŠãƒ¬ãƒƒã‚¸ç”Ÿæˆï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰"""
        # æ§‹é€ åŒ–ã•ã‚ŒãŸå†…å®¹ã‚’ç”Ÿæˆ
        content_parts = []

        content_parts.append("## ç™ºç”Ÿäº‹è±¡")
        if self.collected_info["when"]:
            content_parts.append(self.collected_info["when"])
        if self.collected_info["symptom"]:
            content_parts.append(self.collected_info["symptom"])
        content_parts.append("")

        if self.collected_info["system"]:
            content_parts.append("## å¯¾è±¡ã‚·ã‚¹ãƒ†ãƒ ")
            content_parts.append(self.collected_info["system"])
            content_parts.append("")

        if self.collected_info["impact"]:
            content_parts.append("## å½±éŸ¿ç¯„å›²")
            content_parts.append(self.collected_info["impact"])
            content_parts.append("")

        if self.collected_info["response"]:
            content_parts.append("## å¯¾å¿œå†…å®¹")
            content_parts.append(self.collected_info["response"])
            content_parts.append("")

        if self.collected_info["cause"]:
            content_parts.append("## åŸå› ")
            content_parts.append(self.collected_info["cause"])
            content_parts.append("")

        if self.collected_info["measures"]:
            content_parts.append("## ä»Šå¾Œã®å¯¾ç­–")
            content_parts.append(self.collected_info["measures"])
            content_parts.append("")

        content = "\n".join(content_parts)
        title = self.collected_info["title"] or "æ–°è¦ãƒŠãƒ¬ãƒƒã‚¸"

        # ITSMåˆ†é¡
        classification = self.itsm_classifier.classify(title, content)

        # é¡ä¼¼ãƒŠãƒ¬ãƒƒã‚¸æ¤œç´¢
        similar_knowledge = self.db_client.search_knowledge(query=title, limit=5)

        return {
            "type": "knowledge_generated",
            "title": title,
            "content": content,
            "itsm_type": classification["itsm_type"],
            "confidence": classification["confidence"],
            "similar_knowledge": similar_knowledge,
            "conversation_history": self.conversation_history,
            "ai_generated": False,
            "action": "review_or_save",
        }

    def get_ai_answer(self, question: str) -> Dict[str, Any]:
        """
        AIã‚’ä½¿ã£ã¦è³ªå•ã«å›ç­”ï¼ˆAIã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼é€£æºï¼‰

        Args:
            question: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•

        Returns:
            AIç”Ÿæˆã®å›ç­”ã¨æ ¹æ‹ 
        """
        try:
            # AIã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼ã‚’ä½¿ç”¨
            import asyncio

            from src.ai.orchestrator import get_orchestrator

            orchestrator = get_orchestrator()

            # ç¾åœ¨ã®ä¼šè©±ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’è¿½åŠ 
            context = {
                "conversation_history": self.conversation_history[-5:],
                "collected_info": {k: v for k, v in self.collected_info.items() if v},
            }

            # éåŒæœŸå‡¦ç†ã‚’å®Ÿè¡Œï¼ˆæ—¢å­˜ãƒ«ãƒ¼ãƒ—ãŒã‚ã‚Œã°ä½¿ç”¨ï¼‰
            try:
                loop = asyncio.get_event_loop()
                if loop.is_running():
                    # Flask/Gunicornãªã©æ—¢å­˜ãƒ«ãƒ¼ãƒ—å†…ã§å®Ÿè¡Œä¸­ã®å ´åˆ
                    import concurrent.futures

                    with concurrent.futures.ThreadPoolExecutor() as executor:
                        future = executor.submit(
                            asyncio.run, orchestrator.process(question, context)
                        )
                        result = future.result(timeout=30)
                else:
                    result = loop.run_until_complete(
                        orchestrator.process(question, context)
                    )
            except RuntimeError:
                # ãƒ«ãƒ¼ãƒ—ãŒãªã„å ´åˆã¯æ–°è¦ä½œæˆ
                result = asyncio.run(orchestrator.process(question, context))

            return {
                "success": True,
                "answer": result.answer,
                "evidence": result.evidence,
                "sources": result.sources,
                "confidence": result.confidence,
                "ai_used": result.ai_used,
                "processing_time_ms": result.processing_time_ms,
            }

        except Exception as e:
            logger.error(f"AIå›ç­”ç”Ÿæˆã‚¨ãƒ©ãƒ¼ï¼ˆã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼ï¼‰: {e}")

            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ç›´æ¥Anthropic APIã‚’ä½¿ç”¨
            return self._get_ai_answer_direct(question)

    def _get_ai_answer_direct(self, question: str) -> Dict[str, Any]:
        """
        AIã«ç›´æ¥è³ªå•ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰

        ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼ãŒå¤±æ•—ã—ãŸå ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        """
        try:
            if not self._ai_client:
                return {
                    "success": False,
                    "error": "AIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“",
                    "answer": "AIã‚µãƒ¼ãƒ“ã‚¹ã«æ¥ç¶šã§ãã¾ã›ã‚“ã§ã—ãŸã€‚",
                }

            # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã‚’æ•´å½¢
            context_info = ""
            if any(self.collected_info.values()):
                context_info = "\nã€é–¢é€£æƒ…å ±ã€‘\n" + "\n".join(
                    [f"- {k}: {v}" for k, v in self.collected_info.items() if v]
                )

            prompt = f"""ã‚ãªãŸã¯ITæƒ…ã‚·ã‚¹ã®å°‚é–€å®¶ã§ã™ã€‚ä»¥ä¸‹ã®è³ªå•ã«å¯¾ã—ã¦ã€å®Ÿç”¨çš„ã§åˆ†ã‹ã‚Šã‚„ã™ã„å›ç­”ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚

ã€è³ªå•ã€‘
{question}
{context_info}

ä»¥ä¸‹ã®å½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ï¼š
1. å›ç­”æœ¬æ–‡ï¼ˆç°¡æ½”ã«ï¼‰
2. æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆã‚ã‚Œã°ï¼‰
3. æ³¨æ„ç‚¹ï¼ˆã‚ã‚Œã°ï¼‰

æ—¥æœ¬èªã§å›ç­”ã—ã¦ãã ã•ã„ã€‚"""

            import time

            start_time = time.time()

            if getattr(self, "_ai_provider", None) == "anthropic":
                response = self._ai_client.messages.create(
                    model="claude-sonnet-4-20250514",
                    max_tokens=1500,
                    messages=[{"role": "user", "content": prompt}],
                )
                answer = response.content[0].text
            else:
                response = self._ai_client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=[
                        {"role": "system", "content": "ã‚ãªãŸã¯ITæƒ…ã‚·ã‚¹ã®å°‚é–€å®¶ã§ã™ã€‚"},
                        {"role": "user", "content": prompt},
                    ],
                    max_tokens=1500,
                    temperature=0.5,
                )
                answer = response.choices[0].message.content

            processing_time = int((time.time() - start_time) * 1000)

            return {
                "success": True,
                "answer": answer,
                "evidence": [],
                "sources": [],
                "confidence": 0.7,
                "ai_used": [self._ai_provider or "unknown"],
                "processing_time_ms": processing_time,
            }

        except Exception as e:
            logger.error(f"AIç›´æ¥å›ç­”ã‚¨ãƒ©ãƒ¼: {e}")
            return {
                "success": False,
                "error": str(e),
                "answer": "AIå›ç­”ã®ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã—ã°ã‚‰ãã—ã¦ã‹ã‚‰ãŠè©¦ã—ãã ã•ã„ã€‚",
            }

    def save_knowledge(
        self,
        title: str,
        content: str,
        itsm_type: str,
        created_by: str = "interactive_workflow",
    ) -> Dict[str, Any]:
        """ãƒŠãƒ¬ãƒƒã‚¸ã‚’ä¿å­˜"""
        engine = WorkflowEngine()
        result = engine.process_knowledge(
            title=title, content=content, itsm_type=itsm_type, created_by=created_by
        )
        return result


# ä½¿ç”¨ä¾‹
if __name__ == "__main__":
    workflow = InteractiveKnowledgeCreationWorkflow()

    print("ğŸŒ¸ å¯¾è©±çš„ãƒŠãƒ¬ãƒƒã‚¸ç”Ÿæˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼")
    print("=" * 80)
    print()

    # åˆæœŸå…¥åŠ›
    initial = "æ˜¨æ—¥Webã‚µãƒ¼ãƒãƒ¼ã§ã‚¨ãƒ©ãƒ¼ãŒå‡ºãŸ"
    result = workflow.start_conversation(initial)

    print(f"è³ªå•: {result['question']}")
    print(f"é€²æ—: {result['progress']['percentage']}%")
    print()

    # å¯¾è©±ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
    answers = [
        "12æœˆ30æ—¥ã®14æ™‚é ƒã§ã™",
        "æœ¬ç•ªã®Webã‚µãƒ¼ãƒãƒ¼3å°å…¨éƒ¨ã§ã™",
        "HTTP 503ã‚¨ãƒ©ãƒ¼ãŒå‡ºã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã‚¢ã‚¯ã‚»ã‚¹ã§ããªããªã‚Šã¾ã—ãŸ",
        "å…¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ç´„1000äººã«å½±éŸ¿ã—ã¾ã—ãŸ",
        "Apacheã‚’å†èµ·å‹•ã—ã¦å¾©æ—§ã—ã¾ã—ãŸ",
        "æ¥ç¶šæ•°ã®ä¸Šé™ã«é”ã—ã¦ã„ãŸã“ã¨ãŒåŸå› ã§ã™",
        "max_connectionsã®è¨­å®šã‚’è¦‹ç›´ã—ã¾ã™",
    ]

    for i, answer in enumerate(answers, 1):
        print(f"å›ç­”{i}: {answer}")
        result = workflow.answer_question(answer)

        if result["type"] == "question":
            print(f"è³ªå•: {result['question']}")
            print(f"é€²æ—: {result['progress']['percentage']}%")
            print()
        else:
            print("=" * 80)
            print("âœ… ãƒŠãƒ¬ãƒƒã‚¸ç”Ÿæˆå®Œäº†ï¼")
            print()
            print(f"ã‚¿ã‚¤ãƒˆãƒ«: {result['title']}")
            print(
                f"ITSMã‚¿ã‚¤ãƒ—: {result['itsm_type']} (ä¿¡é ¼åº¦: {result['confidence']:.0%})"
            )
            print()
            print("--- ç”Ÿæˆã•ã‚ŒãŸå†…å®¹ ---")
            print(result["content"])
            print()
            print(f"é¡ä¼¼ãƒŠãƒ¬ãƒƒã‚¸: {len(result['similar_knowledge'])}ä»¶")
            break
