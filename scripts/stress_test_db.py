#!/usr/bin/env python3
"""
Database Stress Test Script
ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ

æŒ‡å®šã—ãŸæ™‚é–“ã¨åŒæ™‚ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°ã§ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¸ã®è² è·ã‚’ã‹ã‘ã€
ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’åé›†ã—ã¾ã™ã€‚

Usage:
    python scripts/stress_test_db.py --users 10 --duration 60
    python scripts/stress_test_db.py --users 10 --duration 300 --env production
    python scripts/stress_test_db.py --report-only
"""

import argparse
import json
import sqlite3
import statistics
import sys
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime
from pathlib import Path
from threading import Lock
from typing import Dict, List, Any

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆ
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))


class StressTestMetrics:
    """ã‚¹ãƒ¬ãƒƒãƒ‰ã‚»ãƒ¼ãƒ•ãªãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†ã‚¯ãƒ©ã‚¹"""

    def __init__(self):
        self._lock = Lock()
        self.operations: Dict[str, List[float]] = {
            'search': [],
            'view': [],
            'create': [],
            'feedback': []
        }
        self.errors: Dict[str, int] = {
            'search': 0,
            'view': 0,
            'create': 0,
            'feedback': 0
        }
        self.start_time = time.time()
        self.end_time = None

    def record(self, operation_type: str, latency_ms: float, success: bool = True):
        """ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¨˜éŒ²ï¼ˆã‚¹ãƒ¬ãƒƒãƒ‰ã‚»ãƒ¼ãƒ•ï¼‰"""
        with self._lock:
            if success:
                self.operations[operation_type].append(latency_ms)
            else:
                self.errors[operation_type] += 1

    def finalize(self):
        """ãƒ†ã‚¹ãƒˆçµ‚äº†ã‚’è¨˜éŒ²"""
        self.end_time = time.time()

    def get_percentile(self, latencies: List[float], percentile: float) -> float:
        """ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«è¨ˆç®—"""
        if not latencies:
            return 0
        sorted_latencies = sorted(latencies)
        idx = int(len(sorted_latencies) * percentile / 100)
        return sorted_latencies[min(idx, len(sorted_latencies) - 1)]

    def generate_report(self) -> Dict[str, Any]:
        """è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        duration = (self.end_time or time.time()) - self.start_time

        report = {
            'summary': {
                'duration_seconds': round(duration, 2),
                'total_operations': sum(len(v) for v in self.operations.values()),
                'total_errors': sum(self.errors.values()),
                'operations_per_second': round(
                    sum(len(v) for v in self.operations.values()) / duration, 2
                ) if duration > 0 else 0
            },
            'by_operation': {}
        }

        for op_type, latencies in self.operations.items():
            if latencies:
                report['by_operation'][op_type] = {
                    'count': len(latencies),
                    'errors': self.errors[op_type],
                    'error_rate': f"{self.errors[op_type] / (len(latencies) + self.errors[op_type]) * 100:.2f}%",
                    'latency_ms': {
                        'avg': round(statistics.mean(latencies), 2),
                        'min': round(min(latencies), 2),
                        'max': round(max(latencies), 2),
                        'p50': round(self.get_percentile(latencies, 50), 2),
                        'p95': round(self.get_percentile(latencies, 95), 2),
                        'p99': round(self.get_percentile(latencies, 99), 2)
                    }
                }

        return report


class StressTestRunner:
    """ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¯ãƒ©ã‚¹"""

    def __init__(self, db_path: Path, num_users: int, duration_seconds: int):
        self.db_path = db_path
        self.num_users = num_users
        self.duration_seconds = duration_seconds
        self.metrics = StressTestMetrics()
        self.running = True

    def get_connection(self) -> sqlite3.Connection:
        """DBæ¥ç¶šã‚’å–å¾—"""
        conn = sqlite3.connect(str(self.db_path), timeout=30.0)
        conn.row_factory = sqlite3.Row
        conn.execute("PRAGMA journal_mode=WAL")
        conn.execute("PRAGMA busy_timeout=30000")
        return conn

    def operation_search(self, user_id: int) -> bool:
        """æ¤œç´¢ã‚ªãƒšãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
        start_time = time.time()
        queries = ['VPN', 'ãƒ¡ãƒ¼ãƒ«', 'Windows', 'ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£', 'ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯']
        query = queries[user_id % len(queries)]

        try:
            conn = self.get_connection()
            cursor = conn.cursor()

            cursor.execute("""
                SELECT ke.id, ke.title
                FROM knowledge_entries ke
                JOIN knowledge_fts fts ON ke.id = fts.rowid
                WHERE knowledge_fts MATCH ?
                LIMIT 10
            """, (query,))
            cursor.fetchall()

            cursor.execute("""
                INSERT INTO search_history (search_query, search_type, user_id)
                VALUES (?, 'stress_test', ?)
            """, (query, f"stress_user_{user_id}"))
            conn.commit()
            conn.close()

            latency_ms = (time.time() - start_time) * 1000
            self.metrics.record('search', latency_ms, True)
            return True

        except Exception as e:
            latency_ms = (time.time() - start_time) * 1000
            self.metrics.record('search', latency_ms, False)
            return False

    def operation_view(self, user_id: int, knowledge_ids: List[int]) -> bool:
        """é–²è¦§ã‚ªãƒšãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
        if not knowledge_ids:
            return False

        start_time = time.time()
        kid = knowledge_ids[user_id % len(knowledge_ids)]

        try:
            conn = self.get_connection()
            cursor = conn.cursor()

            cursor.execute("""
                SELECT * FROM knowledge_entries WHERE id = ?
            """, (kid,))
            cursor.fetchone()

            cursor.execute("""
                INSERT INTO knowledge_usage_stats (knowledge_id, user_id, action_type)
                VALUES (?, ?, 'view')
            """, (kid, f"stress_user_{user_id}"))
            conn.commit()
            conn.close()

            latency_ms = (time.time() - start_time) * 1000
            self.metrics.record('view', latency_ms, True)
            return True

        except Exception as e:
            latency_ms = (time.time() - start_time) * 1000
            self.metrics.record('view', latency_ms, False)
            return False

    def operation_create(self, user_id: int, iteration: int) -> bool:
        """ä½œæˆã‚ªãƒšãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
        start_time = time.time()
        max_retries = 3

        for retry in range(max_retries):
            try:
                conn = self.get_connection()
                cursor = conn.cursor()

                cursor.execute("""
                    INSERT INTO knowledge_entries (
                        title, itsm_type, content, created_by
                    )
                    VALUES (?, 'Other', ?, ?)
                """, (
                    f"StressTest {user_id}-{iteration}-{int(time.time())}",
                    "Stress test content",
                    f"stress_test_user_{user_id}"
                ))
                conn.commit()
                conn.close()

                latency_ms = (time.time() - start_time) * 1000
                self.metrics.record('create', latency_ms, True)
                return True

            except sqlite3.OperationalError as e:
                if "database is locked" in str(e) and retry < max_retries - 1:
                    time.sleep(0.1 * (retry + 1))
                    continue
                latency_ms = (time.time() - start_time) * 1000
                self.metrics.record('create', latency_ms, False)
                return False

            except Exception as e:
                latency_ms = (time.time() - start_time) * 1000
                self.metrics.record('create', latency_ms, False)
                return False

        return False

    def operation_feedback(self, user_id: int, knowledge_ids: List[int]) -> bool:
        """ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚ªãƒšãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
        if not knowledge_ids:
            return False

        start_time = time.time()
        kid = knowledge_ids[user_id % len(knowledge_ids)]

        try:
            conn = self.get_connection()
            cursor = conn.cursor()

            cursor.execute("""
                INSERT INTO knowledge_feedback (knowledge_id, user_id, rating, feedback_type)
                VALUES (?, ?, ?, 'helpful')
            """, (kid, f"stress_user_{user_id}", (user_id % 5) + 1))
            conn.commit()
            conn.close()

            latency_ms = (time.time() - start_time) * 1000
            self.metrics.record('feedback', latency_ms, True)
            return True

        except Exception as e:
            latency_ms = (time.time() - start_time) * 1000
            self.metrics.record('feedback', latency_ms, False)
            return False

    def user_workload(self, user_id: int, knowledge_ids: List[int]):
        """1ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰"""
        iteration = 0
        while self.running:
            # ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰é…åˆ†: 50%æ¤œç´¢ã€30%é–²è¦§ã€10%ä½œæˆã€10%ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯
            op_type = iteration % 10
            if op_type < 5:
                self.operation_search(user_id)
            elif op_type < 8:
                self.operation_view(user_id, knowledge_ids)
            elif op_type < 9:
                self.operation_create(user_id, iteration)
            else:
                self.operation_feedback(user_id, knowledge_ids)

            iteration += 1
            time.sleep(0.1)  # 100msé–“éš”

    def run(self) -> Dict[str, Any]:
        """ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ"""
        print(f"\nğŸš€ ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆé–‹å§‹")
        print(f"   DB: {self.db_path}")
        print(f"   ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°: {self.num_users}")
        print(f"   ç¶™ç¶šæ™‚é–“: {self.duration_seconds}ç§’")

        # æ—¢å­˜ã®ãƒŠãƒ¬ãƒƒã‚¸IDã‚’å–å¾—
        conn = self.get_connection()
        cursor = conn.cursor()
        cursor.execute("SELECT id FROM knowledge_entries WHERE status = 'active' LIMIT 100")
        knowledge_ids = [row['id'] for row in cursor.fetchall()]
        conn.close()

        if not knowledge_ids:
            print("âš ï¸  ãƒŠãƒ¬ãƒƒã‚¸ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
            knowledge_ids = [1]

        print(f"   å¯¾è±¡ãƒŠãƒ¬ãƒƒã‚¸æ•°: {len(knowledge_ids)}")
        print()

        # ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚¹ãƒ¬ãƒƒãƒ‰èµ·å‹•
        with ThreadPoolExecutor(max_workers=self.num_users) as executor:
            futures = []
            for user_id in range(self.num_users):
                futures.append(executor.submit(self.user_workload, user_id, knowledge_ids))

            # æŒ‡å®šæ™‚é–“å¾…æ©Ÿ
            start_time = time.time()
            while time.time() - start_time < self.duration_seconds:
                elapsed = time.time() - start_time
                total_ops = sum(len(v) for v in self.metrics.operations.values())
                ops_per_sec = total_ops / elapsed if elapsed > 0 else 0
                print(f"\r   é€²æ—: {elapsed:.0f}/{self.duration_seconds}ç§’ "
                      f"| ç·ã‚ªãƒšãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³: {total_ops} | {ops_per_sec:.1f} ops/sec", end='')
                time.sleep(1)

            # åœæ­¢ã‚·ã‚°ãƒŠãƒ«
            self.running = False

        self.metrics.finalize()
        print("\n")

        # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        self.cleanup()

        return self.metrics.generate_report()

    def cleanup(self):
        """ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        print("ğŸ§¹ ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ä¸­...")
        conn = self.get_connection()
        cursor = conn.cursor()

        cursor.execute("DELETE FROM knowledge_entries WHERE created_by LIKE 'stress_test_user_%'")
        deleted_knowledge = cursor.rowcount

        cursor.execute("DELETE FROM search_history WHERE user_id LIKE 'stress_user_%'")
        deleted_search = cursor.rowcount

        cursor.execute("DELETE FROM knowledge_usage_stats WHERE user_id LIKE 'stress_user_%'")
        deleted_usage = cursor.rowcount

        cursor.execute("DELETE FROM knowledge_feedback WHERE user_id LIKE 'stress_user_%'")
        deleted_feedback = cursor.rowcount

        conn.commit()
        conn.close()

        print(f"   å‰Šé™¤: ãƒŠãƒ¬ãƒƒã‚¸ {deleted_knowledge}ä»¶, æ¤œç´¢å±¥æ­´ {deleted_search}ä»¶, "
              f"ä½¿ç”¨çµ±è¨ˆ {deleted_usage}ä»¶, ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ {deleted_feedback}ä»¶")


def get_db_path(environment: str) -> Path:
    """ç’°å¢ƒã«å¿œã˜ãŸDBãƒ‘ã‚¹ã‚’å–å¾—"""
    db_paths = {
        'development': PROJECT_ROOT / 'db' / 'knowledge_dev.db',
        'production': PROJECT_ROOT / 'db' / 'knowledge.db',
        'test': PROJECT_ROOT / 'db' / 'knowledge_test.db'
    }
    return db_paths.get(environment, db_paths['development'])


def print_report(report: Dict[str, Any]):
    """ãƒ¬ãƒãƒ¼ãƒˆã‚’å‡ºåŠ›"""
    print("\n" + "=" * 60)
    print("ğŸ“Š ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆçµæœãƒ¬ãƒãƒ¼ãƒˆ")
    print("=" * 60)

    summary = report['summary']
    print(f"\nğŸ“‹ ã‚µãƒãƒªãƒ¼:")
    print(f"   å®Ÿè¡Œæ™‚é–“: {summary['duration_seconds']}ç§’")
    print(f"   ç·ã‚ªãƒšãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ•°: {summary['total_operations']}")
    print(f"   ç·ã‚¨ãƒ©ãƒ¼æ•°: {summary['total_errors']}")
    print(f"   ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ: {summary['operations_per_second']} ops/sec")

    print(f"\nğŸ“ˆ ã‚ªãƒšãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³åˆ¥è©³ç´°:")
    for op_type, data in report['by_operation'].items():
        print(f"\n   ã€{op_type.upper()}ã€‘")
        print(f"   å®Ÿè¡Œå›æ•°: {data['count']} (ã‚¨ãƒ©ãƒ¼: {data['errors']}, ã‚¨ãƒ©ãƒ¼ç‡: {data['error_rate']})")
        latency = data['latency_ms']
        print(f"   ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·: avg={latency['avg']}ms, p50={latency['p50']}ms, "
              f"p95={latency['p95']}ms, p99={latency['p99']}ms, max={latency['max']}ms")

    print("\n" + "=" * 60)

    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åŸºæº–ã¨ã®æ¯”è¼ƒ
    print("\nğŸ“ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åŸºæº–ãƒã‚§ãƒƒã‚¯:")
    targets = {
        'search': {'p50': 200, 'p95': 500},
        'view': {'p50': 50, 'p95': 150},
        'create': {'p50': 2000, 'p95': 5000},
        'feedback': {'p50': 100, 'p95': 300}
    }

    for op_type, data in report['by_operation'].items():
        if op_type in targets:
            target = targets[op_type]
            p50_ok = data['latency_ms']['p50'] <= target['p50']
            p95_ok = data['latency_ms']['p95'] <= target['p95']
            status = "âœ…" if p50_ok and p95_ok else "âš ï¸"
            print(f"   {status} {op_type}: P50 {'OK' if p50_ok else 'NG'}, P95 {'OK' if p95_ok else 'NG'}")


def main():
    parser = argparse.ArgumentParser(
        description='ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä¾‹:
  python scripts/stress_test_db.py --users 10 --duration 60
  python scripts/stress_test_db.py --users 10 --duration 300 --env production
        """
    )

    parser.add_argument('--users', '-u', type=int, default=10,
                        help='åŒæ™‚ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•° (default: 10)')
    parser.add_argument('--duration', '-d', type=int, default=60,
                        help='ãƒ†ã‚¹ãƒˆç¶™ç¶šæ™‚é–“ï¼ˆç§’ï¼‰ (default: 60)')
    parser.add_argument('--env', '-e', choices=['development', 'production', 'test'],
                        default='test', help='å®Ÿè¡Œç’°å¢ƒ (default: test)')
    parser.add_argument('--output', '-o', help='JSONãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«')

    args = parser.parse_args()

    db_path = get_db_path(args.env)

    if not db_path.exists():
        print(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {db_path}")
        print(f"   å…ˆã« init_db.py ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
        sys.exit(1)

    # ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    runner = StressTestRunner(db_path, args.users, args.duration)
    report = runner.run()

    # ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›
    print_report(report)

    # JSONãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
    if args.output:
        output_path = Path(args.output)
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        print(f"\nğŸ“„ JSONãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜ã—ã¾ã—ãŸ: {output_path}")


if __name__ == "__main__":
    main()
