#!/usr/bin/env python3
"""
è‡ªå‹•ã‚¨ãƒ©ãƒ¼æ¤œçŸ¥ãƒ»ä¿®å¾©ãƒ‡ãƒ¼ãƒ¢ãƒ³
5åˆ†é–“éš”ãƒ»ç„¡é™ãƒ«ãƒ¼ãƒ—ã§ã‚·ã‚¹ãƒ†ãƒ ã‚’ç›£è¦–ã—ã€ã‚¨ãƒ©ãƒ¼ã‚’è‡ªå‹•ä¿®å¾©

ä»•æ§˜æ›¸: 19_è‡ªå‹•ã‚¨ãƒ©ãƒ¼æ¤œçŸ¥ä¿®å¾©ã‚·ã‚¹ãƒ†ãƒ ä»•æ§˜æ›¸.md

åŸºæœ¬ä»•æ§˜:
- æ¤œçŸ¥ãƒ«ãƒ¼ãƒ—å›æ•°: 15å›/ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
- å¾…æ©Ÿæ™‚é–“: 5åˆ†ï¼ˆã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³é–“ï¼‰
- å‹•ä½œãƒ¢ãƒ¼ãƒ‰: ç„¡é™ãƒ«ãƒ¼ãƒ—ï¼ˆæ°¸ç¶šå®Ÿè¡Œï¼‰
- å®Ÿè¡Œé–“éš”: ç´„2ç§’ï¼ˆãƒ«ãƒ¼ãƒ—é–“ï¼‰ã€5åˆ†ï¼ˆã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³é–“ï¼‰
- æœ€å¤§ãƒªãƒˆãƒ©ã‚¤: 3å›ï¼ˆåŒä¸€ã‚¨ãƒ©ãƒ¼ï¼‰
- ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³: 300ç§’ï¼ˆ5åˆ†ï¼‰ï¼ˆåŒä¸€ã‚¨ãƒ©ãƒ¼å†ä¿®å¾©ç¦æ­¢ï¼‰
"""

import argparse
import json
import logging
import os
import re
import shutil
import signal
import sqlite3
import subprocess
import sys
import time
from collections import defaultdict
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from pathlib import Path
from typing import Any, Dict, List, Optional, Set, Tuple

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
SCRIPT_DIR = Path(__file__).parent.absolute()
PROJECT_ROOT = SCRIPT_DIR.parent
sys.path.insert(0, str(PROJECT_ROOT))

from health_monitor import HealthMonitor


@dataclass
class DetectedError:
    """æ¤œå‡ºã•ã‚ŒãŸã‚¨ãƒ©ãƒ¼"""
    id: str
    name: str
    pattern: str
    severity: str
    auto_fix: bool
    actions: List[Dict[str, Any]]
    source_file: str
    matched_line: str
    timestamp: str = field(default_factory=lambda: datetime.now().isoformat())


@dataclass
class FixResult:
    """ä¿®å¾©çµæœ"""
    error_id: str
    success: bool
    actions_executed: List[Dict[str, Any]]
    message: str
    timestamp: str = field(default_factory=lambda: datetime.now().isoformat())


class AutoFixDaemon:
    """
    ã‚¨ãƒ©ãƒ¼è‡ªå‹•æ¤œçŸ¥ãƒ»è‡ªå‹•ä¿®å¾©ãƒ‡ãƒ¼ãƒ¢ãƒ³

    å‹•ä½œãƒ•ãƒ­ãƒ¼:
    1. 15å›ã®æ¤œçŸ¥ã‚µã‚¤ã‚¯ãƒ«ã‚’å®Ÿè¡Œ
    2. å„ã‚µã‚¤ã‚¯ãƒ«ã§:
       - ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ
       - ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚¹ã‚­ãƒ£ãƒ³
       - ã‚¨ãƒ©ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°
       - è‡ªå‹•ä¿®å¾©å®Ÿè¡Œ
    3. 5åˆ†é–“å¾…æ©Ÿ
    4. 1ã«æˆ»ã‚‹ï¼ˆç„¡é™ãƒ«ãƒ¼ãƒ—ï¼‰
    """

    # å®šæ•°
    DEFAULT_LOOP_COUNT = 15
    DEFAULT_WAIT_MINUTES = 5
    CYCLE_INTERVAL_SECONDS = 2
    MAX_LOG_LINES = 1000
    COOLDOWN_PERIOD = 300  # 5åˆ†

    def __init__(
        self,
        config_path: Optional[str] = None,
        log_file: Optional[str] = None
    ):
        """
        åˆæœŸåŒ–

        Args:
            config_path: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            log_file: ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        """
        self.project_root = PROJECT_ROOT
        self.config_path = config_path or str(SCRIPT_DIR / "error_patterns.json")
        self.log_file = log_file or str(PROJECT_ROOT / "logs" / "auto_fix.log")

        # ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        Path(self.log_file).parent.mkdir(parents=True, exist_ok=True)

        self.config = self._load_config()
        self.logger = self._setup_logger()
        self.health_monitor = HealthMonitor(config_path=self.config_path)

        # ä¿®å¾©å±¥æ­´ï¼ˆã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ç®¡ç†ç”¨ï¼‰
        self.fix_history: Dict[str, datetime] = {}
        # ãƒªãƒˆãƒ©ã‚¤ã‚«ã‚¦ãƒ³ãƒˆ
        self.retry_counts: Dict[str, int] = defaultdict(int)
        # åœæ­¢ãƒ•ãƒ©ã‚°
        self.running = True

        # ã‚·ã‚°ãƒŠãƒ«ãƒãƒ³ãƒ‰ãƒ©è¨­å®š
        signal.signal(signal.SIGTERM, self._signal_handler)
        signal.signal(signal.SIGINT, self._signal_handler)

        self.logger.info("AutoFixDaemon initialized")
        self.logger.info(f"Project root: {self.project_root}")
        self.logger.info(f"Config: {self.config_path}")

    def _signal_handler(self, signum, frame):
        """ã‚·ã‚°ãƒŠãƒ«ãƒãƒ³ãƒ‰ãƒ©"""
        self.logger.info(f"Received signal {signum}, shutting down gracefully...")
        self.running = False

    def _setup_logger(self) -> logging.Logger:
        """ãƒ­ã‚¬ãƒ¼ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
        logger = logging.getLogger("AutoFixDaemon")
        logger.setLevel(logging.INFO)

        # æ—¢å­˜ãƒãƒ³ãƒ‰ãƒ©ã‚’ã‚¯ãƒªã‚¢
        logger.handlers.clear()

        # ãƒ•ã‚©ãƒ¼ãƒãƒƒã‚¿
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - [%(levelname)s] - %(message)s'
        )

        # ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒ³ãƒ‰ãƒ©
        file_handler = logging.FileHandler(self.log_file, encoding='utf-8')
        file_handler.setFormatter(formatter)
        logger.addHandler(file_handler)

        # ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ãƒãƒ³ãƒ‰ãƒ©
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(formatter)
        logger.addHandler(console_handler)

        return logger

    def _load_config(self) -> Dict[str, Any]:
        """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿"""
        try:
            with open(self.config_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except (FileNotFoundError, json.JSONDecodeError) as e:
            print(f"Warning: Failed to load config: {e}")
            return {"error_patterns": [], "auto_fix_config": {}}

    def scan_logs(self, log_paths: Optional[List[str]] = None) -> List[DetectedError]:
        """
        ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¹ã‚­ãƒ£ãƒ³ã—ã¦ã‚¨ãƒ©ãƒ¼ã‚’æ¤œå‡º

        Args:
            log_paths: ã‚¹ã‚­ãƒ£ãƒ³å¯¾è±¡ã®ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹

        Returns:
            æ¤œå‡ºã•ã‚ŒãŸã‚¨ãƒ©ãƒ¼ã®ãƒªã‚¹ãƒˆ
        """
        if log_paths is None:
            log_paths = self.config.get("monitored_log_files", [
                "logs/app.log",
                "logs/auto_fix.log",
                "logs/workflow.log"
            ])

        detected_errors = []
        error_patterns = self.config.get("error_patterns", [])

        for log_path in log_paths:
            full_path = self.project_root / log_path

            if not full_path.exists():
                continue

            try:
                # æœ€å¾Œã®1000è¡Œã‚’èª­ã¿è¾¼ã¿
                lines = self._read_last_lines(full_path, self.MAX_LOG_LINES)

                for line in lines:
                    for pattern_config in error_patterns:
                        pattern = pattern_config.get("pattern", "")
                        try:
                            if re.search(pattern, line, re.IGNORECASE):
                                error = DetectedError(
                                    id=pattern_config.get("id", "unknown"),
                                    name=pattern_config.get("name", "Unknown Error"),
                                    pattern=pattern,
                                    severity=pattern_config.get("severity", "warning"),
                                    auto_fix=pattern_config.get("auto_fix", False),
                                    actions=pattern_config.get("actions", []),
                                    source_file=str(log_path),
                                    matched_line=line[:200]  # æœ€å¤§200æ–‡å­—
                                )
                                detected_errors.append(error)
                                break  # åŒã˜è¡Œã«è¤‡æ•°ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒã¯é¿ã‘ã‚‹
                        except re.error:
                            continue

            except Exception as e:
                self.logger.warning(f"Failed to scan log {log_path}: {e}")

        return detected_errors

    def _read_last_lines(self, file_path: Path, n: int) -> List[str]:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã®æœ€å¾Œnè¡Œã‚’èª­ã¿è¾¼ã¿"""
        try:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                # åŠ¹ç‡çš„ã«æœ€å¾Œã®nè¡Œã‚’å–å¾—
                lines = []
                for line in f:
                    lines.append(line.strip())
                    if len(lines) > n:
                        lines.pop(0)
                return lines
        except Exception:
            return []

    def is_in_cooldown(self, error_id: str) -> bool:
        """
        ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³æœŸé–“ä¸­ã‹ã©ã†ã‹ã‚’ç¢ºèª

        Args:
            error_id: ã‚¨ãƒ©ãƒ¼ID

        Returns:
            ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ä¸­ãªã‚‰True
        """
        if error_id not in self.fix_history:
            return False

        last_fix_time = self.fix_history[error_id]
        cooldown_period = self.config.get("auto_fix_config", {}).get(
            "cooldown_period", self.COOLDOWN_PERIOD
        )

        return datetime.now() - last_fix_time < timedelta(seconds=cooldown_period)

    def execute_action(self, action: Dict[str, Any]) -> Tuple[bool, str]:
        """
        ä¿®å¾©ã‚¢ã‚¯ã‚·ãƒ§ãƒ³å®Ÿè¡Œ

        Args:
            action: ã‚¢ã‚¯ã‚·ãƒ§ãƒ³å®šç¾©

        Returns:
            (æˆåŠŸãƒ•ãƒ©ã‚°, ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸)
        """
        action_type = action.get("type", "")
        description = action.get("description", action_type)

        self.logger.info(f"Executing action: {action_type} - {description}")

        try:
            if action_type == "service_restart":
                return self._action_service_restart(action)
            elif action_type == "log_rotate":
                return self._action_log_rotate(action)
            elif action_type == "cache_clear":
                return self._action_cache_clear(action)
            elif action_type == "temp_file_cleanup":
                return self._action_temp_file_cleanup(action)
            elif action_type == "create_missing_dirs":
                return self._action_create_missing_dirs(action)
            elif action_type == "fix_permissions":
                return self._action_fix_permissions(action)
            elif action_type == "check_port":
                return self._action_check_port(action)
            elif action_type == "kill_process_on_port":
                return self._action_kill_process_on_port(action)
            elif action_type == "database_vacuum":
                return self._action_database_vacuum(action)
            elif action_type == "backup_and_fix_json":
                return self._action_backup_and_fix_json(action)
            elif action_type == "old_file_cleanup":
                return self._action_old_file_cleanup(action)
            elif action_type == "alert":
                return self._action_alert(action)
            elif action_type == "log_analysis":
                return self._action_log_analysis(action)
            else:
                return False, f"Unknown action type: {action_type}"

        except Exception as e:
            return False, f"Action failed: {str(e)}"

    def _action_service_restart(self, action: Dict) -> Tuple[bool, str]:
        """ã‚µãƒ¼ãƒ“ã‚¹å†èµ·å‹•"""
        service = action.get("service", "mirai-knowledge")
        env = os.environ.get("ENVIRONMENT", "production")

        # ç’°å¢ƒã«å¿œã˜ãŸã‚µãƒ¼ãƒ“ã‚¹å
        if env == "development":
            service_name = f"{service}-dev"
        else:
            service_name = f"{service}-prod"

        try:
            result = subprocess.run(
                ["sudo", "systemctl", "restart", service_name],
                capture_output=True,
                text=True,
                timeout=60
            )
            if result.returncode == 0:
                return True, f"Service {service_name} restarted successfully"
            else:
                return False, f"Failed to restart {service_name}: {result.stderr}"
        except subprocess.TimeoutExpired:
            return False, f"Service restart timed out"
        except FileNotFoundError:
            return False, "systemctl not found"

    def _action_log_rotate(self, action: Dict) -> Tuple[bool, str]:
        """ãƒ­ã‚°ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³"""
        max_size_mb = self.config.get("auto_fix_config", {}).get("max_log_size_mb", 10)
        max_size_bytes = max_size_mb * 1024 * 1024
        rotated_count = 0

        log_dir = self.project_root / "logs"
        if log_dir.exists():
            for log_file in log_dir.glob("*.log"):
                try:
                    if log_file.stat().st_size > max_size_bytes:
                        # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
                        backup_name = f"{log_file.stem}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
                        backup_path = log_file.parent / backup_name
                        shutil.copy2(log_file, backup_path)

                        # å…ƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¯ãƒªã‚¢
                        with open(log_file, 'w') as f:
                            f.write(f"# Log rotated at {datetime.now().isoformat()}\n")

                        rotated_count += 1
                except Exception as e:
                    self.logger.warning(f"Failed to rotate {log_file}: {e}")

        return True, f"Rotated {rotated_count} log files"

    def _action_cache_clear(self, action: Dict) -> Tuple[bool, str]:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢"""
        cleared_count = 0

        # __pycache__ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ã‚¯ãƒªã‚¢
        for cache_dir in self.project_root.rglob("__pycache__"):
            try:
                shutil.rmtree(cache_dir)
                cleared_count += 1
            except Exception:
                pass

        # .pytest_cache
        pytest_cache = self.project_root / ".pytest_cache"
        if pytest_cache.exists():
            try:
                shutil.rmtree(pytest_cache)
                cleared_count += 1
            except Exception:
                pass

        return True, f"Cleared {cleared_count} cache directories"

    def _action_temp_file_cleanup(self, action: Dict) -> Tuple[bool, str]:
        """ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤"""
        paths = action.get("paths", [])
        deleted_count = 0

        for pattern in paths:
            if pattern.startswith("/tmp/"):
                # ã‚·ã‚¹ãƒ†ãƒ ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«
                for f in Path("/tmp").glob(pattern.replace("/tmp/", "")):
                    try:
                        if f.is_file():
                            f.unlink()
                            deleted_count += 1
                    except Exception:
                        pass
            else:
                # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå†…
                for f in self.project_root.glob(pattern):
                    try:
                        if f.is_file():
                            f.unlink()
                            deleted_count += 1
                    except Exception:
                        pass

        return True, f"Deleted {deleted_count} temporary files"

    def _action_create_missing_dirs(self, action: Dict) -> Tuple[bool, str]:
        """ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ"""
        directories = action.get("directories", [])
        created_count = 0

        for dir_path in directories:
            full_path = self.project_root / dir_path
            try:
                full_path.mkdir(parents=True, exist_ok=True)
                created_count += 1
            except Exception as e:
                self.logger.warning(f"Failed to create directory {dir_path}: {e}")

        return True, f"Created/verified {created_count} directories"

    def _action_fix_permissions(self, action: Dict) -> Tuple[bool, str]:
        """æ¨©é™ä¿®æ­£"""
        paths = action.get("paths", [])
        mode = action.get("mode", "755")
        fixed_count = 0

        for path_pattern in paths:
            full_path = self.project_root / path_pattern

            try:
                if full_path.exists():
                    os.chmod(full_path, int(mode, 8))
                    fixed_count += 1
            except Exception as e:
                self.logger.warning(f"Failed to fix permissions for {path_pattern}: {e}")

        return True, f"Fixed permissions for {fixed_count} paths"

    def _action_check_port(self, action: Dict) -> Tuple[bool, str]:
        """ãƒãƒ¼ãƒˆç¢ºèª"""
        port = action.get("port", 8888)
        result = self.health_monitor.check_port(port)
        return True, f"Port {port}: {result.status}"

    def _action_kill_process_on_port(self, action: Dict) -> Tuple[bool, str]:
        """ãƒãƒ¼ãƒˆä½¿ç”¨ãƒ—ãƒ­ã‚»ã‚¹çµ‚äº†"""
        port = action.get("port", 8888)

        try:
            # lsofã§ãƒ—ãƒ­ã‚»ã‚¹ã‚’ç‰¹å®š
            result = subprocess.run(
                ["lsof", "-t", f"-i:{port}"],
                capture_output=True,
                text=True
            )
            pids = result.stdout.strip().split()

            killed = 0
            for pid in pids:
                try:
                    subprocess.run(["kill", "-9", pid], check=True)
                    killed += 1
                except Exception:
                    pass

            return True, f"Killed {killed} processes on port {port}"
        except Exception as e:
            return False, f"Failed to kill processes: {e}"

    def _action_database_vacuum(self, action: Dict) -> Tuple[bool, str]:
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹VACUUM"""
        db_path = self.config.get("project_config", {}).get("db_path", "db/knowledge.db")
        full_path = self.project_root / db_path

        if not full_path.exists():
            return False, f"Database not found: {db_path}"

        try:
            conn = sqlite3.connect(str(full_path))
            conn.execute("VACUUM")
            conn.close()
            return True, f"Database VACUUM completed: {db_path}"
        except Exception as e:
            return False, f"VACUUM failed: {e}"

    def _action_backup_and_fix_json(self, action: Dict) -> Tuple[bool, str]:
        """JSONãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ»ä¿®å¾©"""
        # ä¸»è¦ãªJSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
        json_files = list(self.project_root.glob("**/*.json"))
        backed_up = 0

        for json_file in json_files[:10]:  # æœ€å¤§10ãƒ•ã‚¡ã‚¤ãƒ«
            try:
                backup_path = json_file.with_suffix(".json.bak")
                shutil.copy2(json_file, backup_path)
                backed_up += 1
            except Exception:
                pass

        return True, f"Backed up {backed_up} JSON files"

    def _action_old_file_cleanup(self, action: Dict) -> Tuple[bool, str]:
        """å¤ã„ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤"""
        paths = action.get("paths", ["backups/"])
        days = action.get("days", 30)
        cutoff_time = datetime.now() - timedelta(days=days)
        deleted_count = 0

        for path_pattern in paths:
            search_path = self.project_root / path_pattern
            if search_path.is_dir():
                for f in search_path.iterdir():
                    try:
                        if f.is_file():
                            mtime = datetime.fromtimestamp(f.stat().st_mtime)
                            if mtime < cutoff_time:
                                f.unlink()
                                deleted_count += 1
                    except Exception:
                        pass

        return True, f"Deleted {deleted_count} old files (older than {days} days)"

    def _action_alert(self, action: Dict) -> Tuple[bool, str]:
        """ã‚¢ãƒ©ãƒ¼ãƒˆé€ä¿¡"""
        description = action.get("description", "Alert triggered")

        # ã‚¢ãƒ©ãƒ¼ãƒˆãƒ­ã‚°ã«è¨˜éŒ²
        alert_log = self.project_root / "logs" / "alerts.log"
        alert_log.parent.mkdir(parents=True, exist_ok=True)

        alert_entry = {
            "timestamp": datetime.now().isoformat(),
            "type": "auto_fix_alert",
            "description": description
        }

        with open(alert_log, 'a', encoding='utf-8') as f:
            f.write(json.dumps(alert_entry, ensure_ascii=False) + "\n")

        return True, f"Alert logged: {description}"

    def _action_log_analysis(self, action: Dict) -> Tuple[bool, str]:
        """ãƒ­ã‚°åˆ†æ"""
        description = action.get("description", "Log analysis")
        self.logger.info(f"Log analysis: {description}")
        return True, f"Log analysis completed: {description}"

    def auto_fix_error(self, error: DetectedError) -> FixResult:
        """
        ã‚¨ãƒ©ãƒ¼ä¿®å¾©ã®ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³

        Args:
            error: æ¤œå‡ºã•ã‚ŒãŸã‚¨ãƒ©ãƒ¼

        Returns:
            FixResult
        """
        # ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ç¢ºèª
        if self.is_in_cooldown(error.id):
            return FixResult(
                error_id=error.id,
                success=False,
                actions_executed=[],
                message=f"Error {error.id} is in cooldown period"
            )

        # è‡ªå‹•ä¿®å¾©ãŒç„¡åŠ¹
        if not error.auto_fix:
            return FixResult(
                error_id=error.id,
                success=False,
                actions_executed=[],
                message=f"Auto-fix is disabled for {error.id}"
            )

        # ãƒªãƒˆãƒ©ã‚¤ä¸Šé™ãƒã‚§ãƒƒã‚¯
        max_retries = self.config.get("auto_fix_config", {}).get("max_retries", 3)
        if self.retry_counts[error.id] >= max_retries:
            return FixResult(
                error_id=error.id,
                success=False,
                actions_executed=[],
                message=f"Max retries ({max_retries}) reached for {error.id}"
            )

        # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆï¼ˆè¨­å®šã•ã‚Œã¦ã„ã‚‹å ´åˆï¼‰
        backup_before_fix = self.config.get("auto_fix_config", {}).get("backup_before_fix", True)
        if backup_before_fix:
            self._create_backup()

        # ã‚¢ã‚¯ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
        actions_executed = []
        all_success = True

        for action in error.actions:
            success, message = self.execute_action(action)
            actions_executed.append({
                "type": action.get("type"),
                "success": success,
                "message": message
            })

            if not success:
                all_success = False
                self.logger.warning(f"Action failed: {action.get('type')} - {message}")

        # ä¿®å¾©å±¥æ­´ã‚’æ›´æ–°
        self.fix_history[error.id] = datetime.now()

        if all_success:
            self.retry_counts[error.id] = 0  # ãƒªã‚»ãƒƒãƒˆ
        else:
            self.retry_counts[error.id] += 1

        return FixResult(
            error_id=error.id,
            success=all_success,
            actions_executed=actions_executed,
            message=f"Executed {len(actions_executed)} actions, success: {all_success}"
        )

    def _create_backup(self):
        """ç°¡æ˜“ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ"""
        backup_dir = self.project_root / "backups" / "auto_fix"
        backup_dir.mkdir(parents=True, exist_ok=True)

        # DBãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
        db_path = self.project_root / self.config.get("project_config", {}).get("db_path", "db/knowledge.db")
        if db_path.exists():
            backup_name = f"knowledge_{datetime.now().strftime('%Y%m%d_%H%M%S')}.db"
            try:
                shutil.copy2(db_path, backup_dir / backup_name)
            except Exception as e:
                self.logger.warning(f"Backup failed: {e}")

    def run_detection_cycle(self, cycle_num: int) -> Dict[str, Any]:
        """
        1å›ã®æ¤œçŸ¥ã‚µã‚¤ã‚¯ãƒ«å®Ÿè¡Œ

        Args:
            cycle_num: ã‚µã‚¤ã‚¯ãƒ«ç•ªå·

        Returns:
            ã‚µã‚¤ã‚¯ãƒ«çµæœ
        """
        self.logger.info(f"=== æ¤œçŸ¥ã‚µã‚¤ã‚¯ãƒ« {cycle_num} é–‹å§‹ ===")

        cycle_result = {
            "cycle": cycle_num,
            "timestamp": datetime.now().isoformat(),
            "health_check": None,
            "errors_detected": [],
            "fixes_applied": []
        }

        # 1. ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
        try:
            health_result = self.health_monitor.run_all_checks()
            cycle_result["health_check"] = health_result["overall_status"]

            if health_result["overall_status"] != "healthy":
                self.logger.warning(f"Health check status: {health_result['overall_status']}")
        except Exception as e:
            self.logger.error(f"Health check failed: {e}")
            cycle_result["health_check"] = "error"

        # 2. ãƒ­ã‚°ã‚¹ã‚­ãƒ£ãƒ³
        try:
            errors = self.scan_logs()
            cycle_result["errors_detected"] = [
                {"id": e.id, "name": e.name, "severity": e.severity}
                for e in errors
            ]

            if errors:
                self.logger.warning(f"Detected {len(errors)} errors")

            # 3. è‡ªå‹•ä¿®å¾©
            for error in errors:
                self.logger.info(f"Processing error: {error.name} ({error.severity})")

                fix_result = self.auto_fix_error(error)
                cycle_result["fixes_applied"].append({
                    "error_id": fix_result.error_id,
                    "success": fix_result.success,
                    "message": fix_result.message
                })

                if fix_result.success:
                    self.logger.info(f"Fixed: {error.name}")
                else:
                    self.logger.warning(f"Fix failed: {error.name} - {fix_result.message}")

        except Exception as e:
            self.logger.error(f"Error detection/fix failed: {e}")

        self.logger.info(f"=== æ¤œçŸ¥ã‚µã‚¤ã‚¯ãƒ« {cycle_num} å®Œäº† ===")
        return cycle_result

    def run_continuous(
        self,
        loop_count: int = DEFAULT_LOOP_COUNT,
        wait_minutes: int = DEFAULT_WAIT_MINUTES
    ):
        """
        ç¶™ç¶šçš„ç›£è¦–ãƒ¢ãƒ¼ãƒ‰ï¼ˆç„¡é™ãƒ«ãƒ¼ãƒ—ï¼‰

        Args:
            loop_count: 1ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚ãŸã‚Šã®ãƒ«ãƒ¼ãƒ—å›æ•°
            wait_minutes: ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³é–“ã®å¾…æ©Ÿæ™‚é–“ï¼ˆåˆ†ï¼‰
        """
        self.logger.info("=" * 60)
        self.logger.info("è‡ªå‹•ã‚¨ãƒ©ãƒ¼æ¤œçŸ¥ãƒ»ä¿®å¾©ãƒ‡ãƒ¼ãƒ¢ãƒ³é–‹å§‹")
        self.logger.info(f"ãƒ«ãƒ¼ãƒ—å›æ•°: {loop_count}, å¾…æ©Ÿæ™‚é–“: {wait_minutes}åˆ†")
        self.logger.info("=" * 60)

        iteration = 0

        while self.running:
            iteration += 1
            self.logger.info(f"\n{'='*60}")
            self.logger.info(f"ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ {iteration} é–‹å§‹")
            self.logger.info(f"{'='*60}")

            iteration_results = []

            # loop_count å›ã®ã‚µã‚¤ã‚¯ãƒ«ã‚’å®Ÿè¡Œ
            for cycle in range(1, loop_count + 1):
                if not self.running:
                    break

                result = self.run_detection_cycle(cycle)
                iteration_results.append(result)

                # ã‚µã‚¤ã‚¯ãƒ«é–“å¾…æ©Ÿ
                if cycle < loop_count and self.running:
                    time.sleep(self.CYCLE_INTERVAL_SECONDS)

            # ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚µãƒãƒªãƒ¼
            total_errors = sum(len(r.get("errors_detected", [])) for r in iteration_results)
            total_fixes = sum(len(r.get("fixes_applied", [])) for r in iteration_results)
            successful_fixes = sum(
                sum(1 for f in r.get("fixes_applied", []) if f.get("success"))
                for r in iteration_results
            )

            self.logger.info(f"\nğŸ“Š ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ {iteration} ã‚µãƒãƒªãƒ¼:")
            self.logger.info(f"   ã‚µã‚¤ã‚¯ãƒ«å®Ÿè¡Œæ•°: {len(iteration_results)}")
            self.logger.info(f"   æ¤œå‡ºã‚¨ãƒ©ãƒ¼æ•°: {total_errors}")
            self.logger.info(f"   ä¿®å¾©è©¦è¡Œæ•°: {total_fixes}")
            self.logger.info(f"   ä¿®å¾©æˆåŠŸæ•°: {successful_fixes}")

            # å¾…æ©Ÿ
            if self.running:
                self.logger.info(f"\nâ³ {wait_minutes}åˆ†é–“å¾…æ©Ÿä¸­...")
                wait_seconds = wait_minutes * 60

                # 1ç§’ã”ã¨ã«ãƒã‚§ãƒƒã‚¯ï¼ˆã‚·ã‚°ãƒŠãƒ«å¯¾å¿œï¼‰
                for _ in range(wait_seconds):
                    if not self.running:
                        break
                    time.sleep(1)

        self.logger.info("\nğŸ›‘ ãƒ‡ãƒ¼ãƒ¢ãƒ³åœæ­¢")

    def run_once(self):
        """1å›ã®ã¿å®Ÿè¡Œ"""
        self.logger.info("å˜ç™ºå®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰")
        result = self.run_detection_cycle(1)
        return result


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    parser = argparse.ArgumentParser(
        description="è‡ªå‹•ã‚¨ãƒ©ãƒ¼æ¤œçŸ¥ãƒ»ä¿®å¾©ãƒ‡ãƒ¼ãƒ¢ãƒ³ (Mirai IT Knowledge System)"
    )
    parser.add_argument(
        "--continuous",
        action="store_true",
        help="ç¶™ç¶šçš„ç›£è¦–ãƒ¢ãƒ¼ãƒ‰ï¼ˆç„¡é™ãƒ«ãƒ¼ãƒ—ï¼‰"
    )
    parser.add_argument(
        "--once",
        action="store_true",
        help="1å›ã®ã¿å®Ÿè¡Œ"
    )
    parser.add_argument(
        "--config",
        help="è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹",
        default=None
    )
    parser.add_argument(
        "--log-file",
        help="ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹",
        default=None
    )
    parser.add_argument(
        "--loop-count",
        type=int,
        default=15,
        help="1ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚ãŸã‚Šã®ãƒ«ãƒ¼ãƒ—å›æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 15ï¼‰"
    )
    parser.add_argument(
        "--wait-minutes",
        type=int,
        default=5,
        help="ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³é–“ã®å¾…æ©Ÿæ™‚é–“ï¼ˆåˆ†ï¼‰ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 5ï¼‰"
    )

    args = parser.parse_args()

    daemon = AutoFixDaemon(
        config_path=args.config,
        log_file=args.log_file
    )

    if args.once:
        result = daemon.run_once()
        print(json.dumps(result, indent=2, ensure_ascii=False))
    elif args.continuous:
        daemon.run_continuous(
            loop_count=args.loop_count,
            wait_minutes=args.wait_minutes
        )
    else:
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 1ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆ15ã‚µã‚¤ã‚¯ãƒ«ï¼‰ã®ã¿
        daemon.run_continuous(
            loop_count=args.loop_count,
            wait_minutes=0  # å¾…æ©Ÿãªã—
        )


if __name__ == "__main__":
    main()
